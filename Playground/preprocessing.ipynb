{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'years' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text\u001b[39m.\u001b[39mtranslate(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, additional_punct))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb#W0sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb#W0sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mfor\u001b[39;00m year \u001b[39min\u001b[39;00m years:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb#W0sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading \u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m.csv...\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Niels/Documents/sentiment-analysis/Playground/preprocessing.ipynb#W0sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../csv/\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUTF-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'years' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Remove superfluous information from loaded dataframes.\n",
    "\n",
    "Converts articles to consist of only lowercase characters.\n",
    "Removes commas in names and titles as this causes problems in a csv.\n",
    "Removes stop words from articles, other extraenous punctuation.\n",
    "\n",
    "Additionally contains:\n",
    "df_apply: Function for inplace dataframe modification.\n",
    "remove_stopwords: Function that removes stopwords from a text.\n",
    "remove_punctuation: Function that removes punctuation from a text.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def df_apply(df: pd.DataFrame, column: str, function) -> None:\n",
    "    \"\"\"Wrapper to apply a function in place on a DataFrame.\n",
    "\n",
    "    Allows for a shorter representation of applying a function on a dataframe\n",
    "    with a progress bar. tqdm.progress_apply does not support\n",
    "    in-place modification. By wrapping it, the code becomes more readable.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to be modified\n",
    "        column (str): Column to be modified.\n",
    "        function (str): Function to apply to column.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].progress_apply(function)\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    \"\"\"Return a text with all stopwords removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to remove stopwords from.\n",
    "    \"\"\"\n",
    "    filler: list[str] = stopwords.words(\"dutch\")\n",
    "    return \" \".join([word for word in text.split() if word not in filler])\n",
    "\n",
    "\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"Return a text with all punctuation removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to remove punctuation from.\n",
    "    \"\"\"\n",
    "    additional_punct: str = string.punctuation + '\"“‘—’”\"'\n",
    "    return text.translate(str.maketrans(\"\", \"\", additional_punct))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        print(f\"Loading {year}.csv...\", end=\"\\r\")\n",
    "        df = pd.read_csv(f\"../csv/{year}.csv\", encoding=\"UTF-8\")\n",
    "        print(f\"Loaded {year}.csv. {t.elapsed()}\")\n",
    "\n",
    "        df.dropna(subset=[\"article\"], inplace=True)\n",
    "\n",
    "        print(\"Casting articles to lowercase...\")\n",
    "        df_apply(df, \"article\", lambda x: x.lower())\n",
    "        print(f\"All articles cast to lowercase. {t.collection()}\")\n",
    "\n",
    "        print(\"Removing commas from titles...\")\n",
    "        df_apply(\n",
    "            df,\n",
    "            \"title\",\n",
    "            lambda x: x.translate(str.maketrans(\"\", \"\", \",\"))\n",
    "            if isinstance(x, str)\n",
    "            else x,\n",
    "        )\n",
    "        print(f\"All commas removes from titles. {t.collection()}\")\n",
    "\n",
    "        print(\"Removing commas from author names...\")\n",
    "        df_apply(\n",
    "            df,\n",
    "            \"author\",\n",
    "            lambda x: x.translate(str.maketrans(\"\", \"\", \",\"))\n",
    "            if isinstance(x, str)\n",
    "            else x,\n",
    "        )\n",
    "        print(f\"All commas removed from author names. {t.collection()}\")\n",
    "\n",
    "        print(\"Removing punctuation from articles...\")\n",
    "        df_apply(df, \"article\", lambda x: remove_punctuation(x))\n",
    "        print(f\"All punctuation removed. {t.collection()}\", end=\"\\r\")\n",
    "\n",
    "        print(\"Removing filler words from articles...\")\n",
    "        df_apply(df, \"article\", lambda x: remove_stopwords(x))\n",
    "        print(f\"All filler words removed from articles. {t.collection()}\")\n",
    "\n",
    "        print(f\"Writing dataframe to {year}_01.csv...\", end=\"\\r\")\n",
    "        df.to_csv(f\"../csv/{year}_01.csv\", index=False, encoding=\"UTF-8\")\n",
    "        print(f\"Cleaned dataframe written to {year}_01.csv. {t.collection()}\")\n",
    "\n",
    "    print(\"Succesfully cleaned all csv files!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
